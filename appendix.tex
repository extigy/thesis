\begin{chapter}{Detailed Derivations\label{app:App2}}
\section{\label{appsection:rk4deriv} Derivation of the Runge-Kutta scheme}
Presented here is the derivation of the explicit second-order Runge-Kutta scheme. The ideas and methods easily extend to the forth-order scheme used in this thesis, but in the interests of brevity the entire proof will be given to second order, with the relevant forth order extensions clearly noted.
Let an initial value problem be specified as
\begin{align*}
  \psi'(t) &= f(\psi(t),t),\hspace{0.25in}\psi(t_0) = \psi_0,
\end{align*}
where $t_n = nh$, $h$ is a chosen step size, and $f(\psi(t),t)$ is known. The aim of the scheme is to estimate some $\psi(t_m)$ from the known $\psi(t_0)$ through the application of a single numerical step of size $h$, $m$ times.

For a single application of the numerical step we attempt to find the unknown value of $\psi(t_{n+1})$, which can be written,
\begin{align*}
\psi(t_{n+1}) &= \psi(t_n) + \left[ \psi(t_{n+1}) - \psi(t_n) \right]\\
          &= \psi(t_n) + \int_{t_n}^{t_{n+1}}\!\!f\left(\psi(\tau),\tau\right)\,{\rm d}\tau.
\end{align*}
We now decide to approximate the (difficult to calculate) integral $\int_{t_n}^{t_{n+1}}\!\!f\left(\psi(\tau),\tau\right)\,{\rm d}\tau$ using quadrature, leading to the modified expression,
\begin{equation*}
\psi(t_{n+1}) \approx \psi(t_n) + h\sum\limits_{i=1}^N \omega_i f(t_n+h\nu_i,\psi(t_n+h\nu_i)),
\end{equation*}
where $N$ is the order of the numerical scheme, $\omega_i$ are weights and $\nu_i$ are locations in time positioned between $t_n$ and $t_{n+1}$ inclusive. In this second-order derivation we take $N=2$, a forth-order scheme would alternatively require $N=4$.

We take the first temporal point to be $\nu_1=0$, so that the first term in the sum is
\begin{equation*}
k_1 = hf(t_n,\psi(t_n)).
\end{equation*}
We can then easily calculate the value of $k_1$. A single step in Euler's method tells us that $\psi(t_n+h\nu_2) \approx h\nu_2f(t_n,\psi(t_n))$ and so we write $k_2$ in a form containing $k_1$,
\begin{equation*}
k_2 = hf(t_n+h\nu_2,\psi(t_n+h\nu_2)) \approx hf(t_n+\nu_2h,\psi(t)+\nu_2k_1).
\end{equation*}
For a forth order scheme we would then introduce $k_3$ and $k_4$, following the same methods of writing $k_i$ in previous terms up to $k_{i-1}$. To second order, the quadrature formula becomes
\begin{equation}
\psi(t_{n+1}) \approx \psi(t_n) + \omega_1k_1 + \omega_1k_2.
\end{equation}\label{eq:rka1}
However, note that we still must derive values for the quantities $\nu_{i>1}$ and $\omega_i$.

Consider the Taylor expansion,
\begin{equation*}
\psi(t+h) = \psi(t) + h\psi'(t) + \frac{h^2}{2}\psi''(t) + \cdots,
\end{equation*}
where for the full forth-order derivation, further higher order terms are also considered. We substitute this expansion into the left hand side of Equation \ref{eq:rka1}, which leads to
\begin{equation}
\psi(t_n) + h\psi'(t_n) + \frac{h^2}{2!}\psi''(t_n) + \mathcal{O}(h^3) \approx \psi(t_n) + \omega_1k_1 + \omega_2k_2.
\end{equation}\label{eq:rka2}
Note that
\begin{align*}
\psi'(t_n)  &= f,\\
\psi''(t_n) &= \frac{\partial f}{\partial t} + f\frac{\partial f}{\partial \psi},
\end{align*}
by the definition of $\psi'(t)$ and the total derivative, and where the arguments of $f(t_n,\psi(t_n))$ have been suppressed for notational ease. We then substitute the expressions for $\psi'(t_n)$, $\psi''(t_n)$, $k_1$ and $k_2$ into Equation \ref{eq:rka2},
\begin{equation}
hf + \frac{h^2}{2}\left(\frac{\partial f}{\partial t} + f\frac{\partial f}{\partial \psi}\right) + \mathcal{O}(h^3) = \omega_1hf + \omega_2hf(t_n+\nu_2h,\psi(t)+\nu_2k_1).
\end{equation}\label{eq:rka3}

Now consider the Taylor expansion,
\begin{equation*}
f(t+h,\psi+g) = f(t,\psi) + h\frac{\partial f(t,\psi)}{\partial t} +g\frac{\partial f(t,\psi)}{\partial \psi} + \cdots,
\end{equation*}
where for the full forth-order derivation, further higher-order terms are also considered. We substitute this expansion into Equation \ref{eq:rka3}, including terms up to the required order, and find
\begin{equation}
hf + \frac{h^2}{2!}\left(\frac{\partial f}{\partial t} + f\frac{\partial f}{\partial \psi}\right) + \mathcal{O}(h^3) = \omega_1hf + \omega_2\left( hf + \nu_2h^2 \frac{\partial f}{\partial t} + \nu_2h^2f\frac{\partial f}{\partial \psi} \right)+ \mathcal{O}(h^3).
\end{equation}\label{eq:rka4}
By equating terms on both the right hand side and left hand side of Equation \ref{eq:rka4}, we find that for the second-order Runge-Kutta scheme the following equivalences are required for consistency,
\begin{align*}
\omega_1 + \omega_2 = 1,\\
\nu_2\omega_2 = \frac{1}{2}.
\end{align*}
For the forth-order scheme, more but similar equivalences are required for consistency. The canonical choice for the second-order Runge-Kutta methods is
$\nu_2=1$ and $\omega_1 = \omega_2 = 1/2$. The scheme can then be directly written down,
\begin{equation}
\psi(t_{n+1}) = \psi(t_n) + \frac{k_1}{2} + \frac{k_2}{2} + \mathcal{O}(h^3),
\end{equation}
where $k_1 = hf(t_n,\psi(t_n))$ and $k_2 = hf(t_n+h,\psi(t)+k_1)$.

When this proof outline is followed with $N=4$, the forth-order Runge-Kutta scheme can be found,
\begin{equation}
    \psi(t_{n+1}) = \psi(t_n) + \frac{k_1}{6}+ \frac{k_2}{3}+ \frac{k_3}{3} + \frac{k_4}{6} + \mathcal{O}(h^5),
\end{equation}
where
\begin{equation*}
\begin{split}
    k_1 &= hf(t_n,\psi(t_n)),\\
    k_2 &= hf(t_n+\frac{h}{2},\psi(t_n)+\frac{k_1}{2}),\\
    k_3 &= hf(t_n+\frac{h}{2},\psi(t_n)+\frac{k_2}{2}),\\
    k_4 &= hf(t_n+h,\psi(t_n)+k_3).
\end{split}
\end{equation*}

\section{\label{appsection:gpeqft} Derivation of the Gross-Pitaevskii Equation}
This section derives the GPE following the methodology outlined in \cite{0953-4075-41-20-203002}. We begin by revisiting the quantum field theory formalism used to describe a many-body quantum system \cite{fetter1971quantum}. Such a system is described by an $N$-body wavefunction, $\tilde{\upPsi}(\mathbf{r}_1...\mathbf{r}_N,t)$ which obeys the famous Schr\"odinger equation
\begin{equation}
i \hbar\frac{\partial}{\partial t}\tilde{\upPsi}(\mathbf{r}_1...\mathbf{r}_N,t) = \hat{H}\tilde{\upPsi}(\mathbf{r}_1...\mathbf{r}_N,t),
\label{eq:gpeqftscho}
\end{equation}
where $\mathbf{r}_i$ describes the coordinates of the $i$th body. Consider a closed system containing a dilute, weakly interacting Bose gas of $N$ atoms. Such a system would be described by $\tilde{\upPsi}(\mathbf{r}_1...\mathbf{r}_N,t)$, with a Hamiltonian of the form 
\begin{equation}
\hat{H} = \sum_{k=1}^N\hat{h}_0(\mathbf{r}_k,t) + \frac{1}{2}\sum_{k,l=1}^N \hat{V}(\mathbf{r}_k,\mathbf{r}_l).
\label{eq:gpeqfthamil}
\end{equation}
Here $\hat{h}_0(\mathbf{r},t) = -\frac{\hbar^2}{2m}\nabla^2+V_{\mathrm{ext}}(\mathbf{r},t)$ is a contribution arising from the effects of a single particle in an external potential. We assume in the dilute gas all interactions are binary, and so the second term arises from collisions between 2 atoms. The factor of $\frac{1}{2}$ ensures the effects are only counted once over the entire sum.

We now reformulate this system in a different representation, using the so called `occupation number' orthonormal basis $\ket{n_1...n_\infty}$. This basis arises from the observation that multiple particles sharing an energetically accessible state are indistinguishable. Instead we consider only the number of particles in each state $i$ and denote this $n_i$. Such states often correspond to states with fixed energy $\varepsilon_i$. While the number of states are infinite, our system contains a fixed number of bosons, $N$, implying that there are at most $N$ states occupied.

The wavefunction is mapped into the `occupation number' basis via
\begin{equation*}
\tilde{\upPsi}(\mathbf{r}_1...\mathbf{r}_N,t) \rightarrow \ket{\tilde{\upPsi}(t)}=\sum_{n_1...n_\infty} c(n_1...n_\infty,t)\ket{n_1...n_\infty},
\end{equation*}
with appropriately chosen complex coefficients, $c(n_1...n_\infty,t)$. The values $c$ must follow the particle statistics rules (e.g. for bosons, must be symmetric under swapping of quantum numbers) and be normalised so that the probabilities correctly sum to one. We find that for our bosons,

\begin{equation*}
\int|\tilde{\upPsi}|^2~d\mathbf{r}=1 \Rightarrow \sum_{n_1...n_\infty}|c(n_1...n_\infty,t)|^2\frac{N!}{n_1!...n_\infty!} = 1.
\end{equation*}

In this formulation, note that the state vectors $\ket{n_1...n_\infty}$ are time-independent, and the evolution of the system is entirely encoded in the values of $c(n_1...n_\infty,t)$. As part of the overall picture, we also must describe the movement of bosons between different states or energy levels. It is convenient to visualise this as the simultaneous destruction of a particle in state $j$ and creation of a particle in state $i$, described mathematically using the single particle annihilation and creation operators \cite{schiff1968},
\begin{align*}
&\hat{a}_j\ket{n_1...n_i...n_j...n_\infty} = \sqrt{n_j}\ket{n_1...n_i...n_j-1...n_\infty},\\
&\hat{a}^\dagger_i\ket{n_1...n_i...n_j...n_\infty} = \sqrt{n_i+1}\ket{n_1...n_i+1...n_j...n_\infty},
\end{align*}
which satisfy the bosonic commutation relations,
\begin{equation*}
[\hat{a}_i,\hat{a}_j^\dagger]=\delta_{ij}\hspace{0.5in}[\hat{a}_i,\hat{a}_j]=[\hat{a}_i^\dagger,\hat{a}_j^\dagger]=0.
\end{equation*}
Any single particle changing states can now be described through these operators; a particle moving from state $j$ to state $i$ is described using a single annihilation operator and a single creation operator through the product $\hat{a}_i^\dagger\hat{a}_j$. Similarly, as we decided to simplify the system by considering a dilute gas where all interactions are binary collisions, all interactions can be described by two particles changing state, using the product $\hat{a}_i^\dagger\hat{a}_k^\dagger\hat{a}_j\hat{a}_l$. Using these tools and ideas, the original description in Equations \ref{eq:gpeqftscho} and \ref{eq:gpeqfthamil} is now written

\begin{equation*}
i \hbar\frac{\partial}{\partial t}\ket{\tilde{\upPsi}} = \hat{H}\ket{\tilde{\upPsi}},
\label{eq:gpeqftsecscho}
\end{equation*}
with the Hamiltonian
\begin{equation}
\hat{H} = \sum_{ij}\bra{i}\hat{h}_0\ket{j}\hat{a}_i^\dagger\hat{a}_j + \frac{1}{2}\sum_{ijkl} \bra{ik}\hat{V}\ket{jl}\hat{a}_i^\dagger\hat{a}_k^\dagger\hat{a}_j\hat{a}_l,
\label{eq:gpeqftsechamil}
\end{equation}
where
\begin{align*}
&\bra{i}\hat{h}_0\ket{j} = \int \phi_i^*(\mathbf{r})\hat{h}_0\phi_j(\mathbf{r})~d\mathbf{r},\\
&\bra{ik}\hat{V}\ket{jl} = \frac{1}{2}\left [ (ik|\hat{V}|jl) + (ik|\hat{V}|lj) \right ],\\
&(ik|\hat{V}|jl) = \iint \phi_i^*(\mathbf{r})\phi_k^*(\mathbf{r}')\hat{V}(\mathbf{r}-\mathbf{r}')\phi_l(\mathbf{r}')\phi_j(\mathbf{r})~d\mathbf{r}'d\mathbf{r}.
\end{align*}
For further convenience we introduce the so-called Bose field operators
\begin{align*}
&\hat{\upPsi}(\mathbf{r},t) = \sum_i \hat{a}_i(t)\phi_i(\mathbf{r},t),\\
&\hat{\upPsi}^\dagger(\mathbf{r},t) = \sum_i \hat{a}^\dagger_i(t)\phi_i(\mathbf{r},t),
\end{align*}
which can be thought of as operators that represent the addition or removal of a particle at time $t$ and location $\mathbf{r}$. As with the annihilation and creation operators, the Bose field operators also satisfy the commutation relations,
\begin{equation}
[\hat{\upPsi}(\mathbf{r},t),\hat{\upPsi}^\dagger(\mathbf{r}',t)]=\delta(\mathbf{r}-\mathbf{r}')\hspace{0.3in}[\hat{\upPsi}(\mathbf{r},t),\hat{\upPsi}(\mathbf{r}',t)]=[\hat{\upPsi}^\dagger(\mathbf{r},t),\hat{\upPsi}^\dagger(\mathbf{r}',t)]=0.
\label{eq:gpeqftbfocomm}
\end{equation}
Using these operators, the Hamiltonian in Equation \ref{eq:gpeqftsechamil} can be again rewritten as
\begin{equation}
\begin{split}
\hat{H} &= \int \hat{\upPsi}^\dagger(\mathbf{r},t)\,\hat{h}_0 \hat{\upPsi}(\mathbf{r},t)~d\mathbf{r}\\
&+\frac{1}{2}\iint \hat{\upPsi}^\dagger(\mathbf{r},t)\hat{\upPsi}^\dagger(\mathbf{r}',t)V(\mathbf{r}-\mathbf{r}')\hat{\upPsi}(\mathbf{r}',t)\hat{\upPsi}(\mathbf{r},t)~d\mathbf{r}'d\mathbf{r},
\label{eq:gpeqftbfohamil}
\end{split}
\end{equation}
where, as before, $\hat{h}_0(\mathbf{r}_k,t) = -\frac{\hbar^2}{2m}\nabla^2+V_{\mathrm{ext}}(\mathbf{r},t)$ and $V(\mathbf{r}-\mathbf{r}')$ is the two-body interaction potential.

We now add to our approximations a frequent simplification of the interaction potential and consider all interactions as totally elastic contact collisions. The strength of this interaction is usually taken to be $g=4\pi\hbar^2a/m$, where $a$ is the s-wave scattering length, measured for a particular atom in the lab. Our two-body interaction potential then becomes,
\begin{equation*}
V(\mathbf{r}-\mathbf{r}') = g \delta(\mathbf{r}-\mathbf{r}'),
\end{equation*}
which when inserted into Equation \ref{eq:gpeqftbfohamil} gives the Hamiltonian,
\begin{equation*}
\hat{H} = \int \hat{\upPsi}^\dagger(\mathbf{r},t)\,\hat{h}_0 \hat{\upPsi}(\mathbf{r},t)~d\mathbf{r}+\frac{g}{2}\int \hat{\upPsi}^\dagger(\mathbf{r},t)\hat{\upPsi}^\dagger(\mathbf{r},t)\hat{\upPsi}(\mathbf{r},t)\hat{\upPsi}(\mathbf{r},t)~d\mathbf{r}.
\label{eq:gpeqftvgdhamil}
\end{equation*}

The Bose field operator $\hat{\upPsi}(\mathbf{r},t)$ evolves over time according to the Heisenberg equation of motion
\begin{equation*}
i \hbar\frac{\partial}{\partial t}\hat{\upPsi}(\mathbf{r},t) = [\hat{\upPsi}(\mathbf{r},t), \hat{H}].
\end{equation*}
By expanding out the commutator, using standard commutator identities along with the relations in Equation \ref{eq:gpeqftbfocomm} and integrating out resulting delta functions we find 
\begin{equation}
\begin{split}
i \hbar\frac{\partial}{\partial t}\hat{\upPsi}(\mathbf{r},t) &= \int [\hat{\upPsi}, \hat{\upPsi}^\dagger \hat{h}_0 \hat{\upPsi}]~d\mathbf{r}+ \frac{g}{2}\int[\hat{\upPsi}, \hat{\upPsi}^\dagger\hat{\upPsi}^\dagger\hat{\upPsi}\hat{\upPsi}]~d\mathbf{r}\\
&
\begin{split}
=\int [\hat{\upPsi}, &\hat{\upPsi}^\dagger]\hat{h}_0 \hat{\upPsi} + \hat{\upPsi}^\dagger[\hat{\upPsi},\hat{h}_0 \hat{\upPsi}]~d\mathbf{r}\\
&+\frac{g}{2}\int[\hat{\upPsi},\hat{\upPsi}^\dagger]\hat{\upPsi}^\dagger\hat{\upPsi}\hat{\upPsi}+ \hat{\upPsi}^\dagger[\hat{\upPsi},\hat{\upPsi}^\dagger]\hat{\upPsi}\hat{\upPsi} + \hat{\upPsi}^\dagger\hat{\upPsi}^\dagger[\hat{\upPsi},\hat{\upPsi}\hat{\upPsi}] ~d\mathbf{r}\end{split}\\
&= \hat{h}_0\hat{\upPsi}(\mathbf{r},t) + g\hat{\upPsi}^\dagger(\mathbf{r},t)\hat{\upPsi}(\mathbf{r},t)\hat{\upPsi}(\mathbf{r},t).
\end{split}
\label{eq:gpeqfthem}
\end{equation}
We can continue to simplify the equation of motion by considering a mean-field approach for a single macroscopically occupied state. In the case of Bose-Einstein condensation the lowest energy level is macroscopically occupied and so we decompose the field operator via 
\begin{equation*}
\hat{\upPsi}(\mathbf{r},t) = \hat{\psi}(\mathbf{r},t) + \hat{\delta}(\mathbf{r},t),
\end{equation*}
where $\psi(\mathbf{r},t)$ is a field operator for the condensate and $\hat{\delta}(\mathbf{r},t)$ is a field operator for the non-condensed atoms, whether that be atoms in higher states, atoms residing in the thermal cloud, or atoms influenced by quantum mechanical fluctuations. 

We now make the Bogoliubov approximation \cite{bogo47}, a somewhat violent symmetry breaking approximation in which the condensate field operator is replaced by a classical field, 
\begin{equation*}
\hat{\psi}(\mathbf{r},t) = \psi(\mathbf{r},t) = \sqrt{N_0}\phi_0(\mathbf{r},t),
\end{equation*}
where $N_0$ is the number of particles in the condensate. Written in this way, it is then possible to approximate the condensate density using $n(\mathbf{r},t) = |\psi(\mathbf{r},t)|^2$. Unfortunately a direct consequence of the action is that the physical state described by $\hat{\upPsi}(\mathbf{r},t)$ no longer satisfies the same symmetries as before. In particular, the total number of particles is not conserved. This approximation is justified by the understanding that as the condensate forms, it takes on a single phase, and all the particles in the condensate can be described by a single wavefunction. In addition, it is assumed that if there are many particles in the condensate, the exact value of $N_0$ does not affect the system state significantly, that is, $N_0 \approx N_0+1$. This approximation is essentially equivalent to the statement $\braket{\hat{\upPsi}(\mathbf{r},t)} = \psi(\mathbf{r},t) \ne 0$, where $\braket{...}$ denotes the ensemble average. The non-condensed field operator $\hat{\delta}(\mathbf{r},t)$ remains as an operator in the decomposition, and captures all the fluctuations around $\psi(\mathbf{r},t)$. It is generally assumed that $\braket{\hat{\delta}(\mathbf{r},t)}=0$.

In principle, the classical field $\psi(\mathbf{r},t)$ is interpreted as the condensed atoms , however it can also be interpreted as the condensate atoms along with excitations of the system, as long as the occupation at high energy states $n_{i\gg1}$ and the size of quantum fluctuations are both negligible. The classical field, or c-field, approaches can be used to model finite temperature effects by modelling part of the thermal cloud with highly populated modes below a certain momentum cutoff, explored in Section \ref{section:cfield}.

In the limit of $T\rightarrow0$, all of the particles become part of the condensate, so that $N=N_0$. The contribution from the non-condensate atoms can be neglected, $\hat{\delta}(\mathbf{r},t)=0$, and the field operator is written $\hat{\upPsi}(\mathbf{r},t) = \psi(\mathbf{r},t)$. In this case, the Heisenberg equation of motion in Equation \ref{eq:gpeqfthem} reduces to
\begin{equation*}
\begin{split}
i \hbar\frac{\partial}{\partial t}\psi(\mathbf{r},t) &= \hat{h}_0\psi(\mathbf{r},t) + g\psi^*(\mathbf{r},t)\psi(\mathbf{r},t)\psi(\mathbf{r},t)\\
&= \left ( -\frac{\hbar^2}{2m}\nabla^2+V_{\mathrm{ext}}(\mathbf{r},t) + g|\psi(\mathbf{r},t)|^2 \right ) \psi(\mathbf{r},t),
\end{split}
\end{equation*}
the so-called Gross-Pitaevskii equation (GPE), also known as the non-linear\;Schr\"odinger equation (NLSE).

Finally, note that as the particle number is no longer strictly conserved, calculations should be performed within the grand canonical ensemble \cite{huang1987statistical}. This approach leads to the modified Hamiltonian $\hat{H} \rightarrow \hat{H} -\mu\hat{N}$, where $\mu$ is the chemical potential and $\hat{N}$ is the total number operator. The above derivations can be easily repeated with the modified Hamiltonian to obtain a physically equivalent version of the GPE with a chemical potential term,
\begin{equation}
i \hbar\frac{\partial}{\partial t}\psi(\mathbf{r},t) = \left ( -\frac{\hbar^2}{2m}\nabla^2+V_{\mathrm{ext}}(\mathbf{r},t) + g|\psi(\mathbf{r},t)|^2 - \mu \right ) \psi(\mathbf{r},t).
\end{equation}

\section{\label{appsection:madtrans} Derivation of the Hydrodynamic Equations via the Madelung Transformation}
Inserting the Madelung transformation (Section \ref{section:hydrodynamic}) into the GPE and writing the result in tensor notation yields
\begin{equation*}
  \mathrm{i}\hbar\left( \frac{\partial R}{\partial t} + \mathrm{i}\frac{\partial \theta}{\partial t} R \right)e^{\mathrm{i}\theta} =
  -\frac{\hbar^2}{2m}e^{\mathrm{i}\theta}\left( \frac{\partial^2 R}{\partial x_j^2} + 2\mathrm{i}\frac{\partial \theta}{\partial x_j}\frac{\partial R}{\partial x_j}+
  \mathrm{i}\frac{\partial^2 \theta}{\partial x_j^2}R -  \frac{\partial \theta}{\partial x_j}\frac{\partial \theta}{\partial x_j} R  \right) + gR^3e^{\mathrm{i}\theta} + VRe^{\mathrm{i}\theta}.
\end{equation*}
The real and imaginary parts of the GPE, once divided by $\exp (\mathrm{i}\theta)$, then take the form
\begin{align}
  -\hbar R \frac{\partial \theta}{\partial t} &= -\frac{\hbar^2}{2m}\left( \frac{\partial^2 R}{\partial x_j \partial x_j} - R \frac{\partial \theta}{\partial x_j}\frac{\partial \theta}{\partial x_j}  \right) + gR^3 + VR, \label{eq:MTre}\\
  \hbar \frac{\partial R}{\partial t} &= -\frac{\hbar^2}{2m}\left( 2\frac{\partial \theta}{\partial x_j}\frac{\partial R}{\partial x_j} + R \frac{\partial^2 \theta}{\partial x_j \partial x_j} \right).
  \label{eq:MTim}
\end{align}
Consider Equation (\ref{eq:MTim}) and note that $\rho = mR^2 \Rightarrow \frac{\partial \rho}{\partial t} = 2mR\frac{\partial R}{\partial t}$, allowing us to rewrite the equation in terms of $\rho$,
\begin{align*}
  \frac{\partial \rho}{\partial t} &= -\hbar R\left( 2 \frac{\partial \theta}{\partial x_j} \frac{\partial R}{\partial x_j} + R \frac{\partial^2 \theta}{\partial x_j\partial x_j} \right)\\
  &= -2mR\frac{\partial R}{\partial x_j}\frac{\partial}{\partial x_j}\left( \frac{\hbar}{m} \theta \right) - mR^2 \frac{\partial^2}{\partial x_j \partial x_j}\left(\frac{\hbar}{m}\theta \right)\\
  &= -\frac{\partial \rho}{\partial x_j}\frac{\partial}{\partial x_j}\left( \frac{\hbar}{m} \theta \right) - \rho \frac{\partial^2}{\partial x_j \partial x_j}\left(\frac{\hbar}{m}\theta \right).
\end{align*}
The terms containing the phase can then be directly replaced with the fluid velocity, $v_j = \frac{\partial}{\partial x_j}\left( \frac{\hbar}{m} \theta \right)$.
\begin{align*}
  \frac{\partial \rho}{\partial t} &= -\frac{\partial \rho}{\partial x_j} v_j - \rho \frac{\partial}{\partial x_j} v_j\\
                   &= -\frac{\partial}{\partial x_j} \left( \rho v_j \right).
\end{align*}
Rewritten in vector form the result is a continuity equation,
\begin{equation}
  \frac{\partial \rho}{\partial t} + \nabla(\rho{\bf v}) = 0.
\end{equation}
Now consider Equation (\ref{eq:MTre}), written in the form
\begin{equation*}
\frac{\hbar}{m} \frac{\partial \theta}{\partial t} = \frac{\hbar^2}{2m^2} \left( \frac{1}{R} \frac{\partial^2 R}{\partial x_j \partial x_j} - \frac{\partial \theta}{\partial x_j}\frac{\partial \theta}{\partial x_j}  \right) - \frac{gR^2}{m} - \frac{V}{m}.
\end{equation*}
Note that it can easily be shown $\frac{1}{R} \frac{\partial^2 R}{\partial x_j \partial x_j} = \frac{1}{\sqrt{\rho}}\nabla^2\sqrt{\rho}$ and $\frac{\hbar^2}{2m^2} \frac{\partial \theta}{\partial x_j}\frac{\partial \theta}{\partial x_j} = \frac{v^2}{2} $. It follows that Equation (\ref{eq:MTre}) can be written,

\begin{align*}
&\frac{\hbar}{m} \frac{\partial \theta}{\partial t} = \frac{\hbar^2}{2m^2} \frac{1}{\sqrt{\rho}} \nabla^2\sqrt{\rho} - \frac{v^2}{2} - \frac{gR^2}{m} - \frac{V}{m}\\
&\Rightarrow \frac{\partial}{\partial t}\left(\frac{\hbar}{m} \frac{\partial \theta}{\partial x_k}\right) = \frac{\partial}{\partial x_k}\left(\frac{\hbar^2}{2m^2} \frac{1}{\sqrt{\rho}} \nabla^2\sqrt{\rho} \right)- \frac{\partial}{\partial x_k} \left (\frac{v^2}{2}\right) - \frac{2gR}{m}\frac{\partial R}{\partial x_k} - \frac{1}{m}\frac{\partial V}{\partial x_k}\\
&\Rightarrow \rho\frac{\partial v_k}{\partial t} =\rho \frac{\partial}{\partial x_k}\left(\frac{\hbar^2}{2m^2} \frac{1}{\sqrt{\rho}} \nabla^2\sqrt{\rho} \right)- \rho\frac{\partial}{\partial x_k} \left (\frac{v^2}{2}\right) - 2gR^3\frac{\partial R}{\partial x_k} - \rho\frac{1}{m}\frac{\partial V}{\partial x_k}.
\end{align*}

By noticing that $p = \frac{1}{2}g \left ( \frac{\rho}{m} \right ) ^2 = \frac{gR^4}{2}$ we can write $\frac{\partial p}{\partial x_k} = 2gR^3\frac{\partial R}{\partial x_k}$ and then,
\begin{equation*}
\rho\frac{\partial v_k}{\partial t} + \rho\frac{\partial}{\partial x_k} \left (\frac{v^2}{2}\right) =\rho \frac{\partial}{\partial x_k}\left(\frac{\hbar^2}{2m^2} \frac{1}{\sqrt{\rho}} \nabla^2\sqrt{\rho} \right) - \frac{\partial p}{\partial x_k} - mR^2\frac{\partial}{\partial x_k}\left ( \frac{V}{m}\right ).
\end{equation*}

We now now use the following two results,
\begin{align*}
v_j \frac{\partial}{\partial x_j}v_k &= \frac{\partial}{\partial x_k}\left ( \frac{v_jv_j}{2}\right )\\
2\frac{\partial}{\partial x_k}\left( \frac{1}{\sqrt{\rho}} \frac{\partial^2}{\partial x_j \partial x_j} \sqrt{\rho}\right) &= \frac{1}{\rho} \frac{\partial}{\partial x_j}\rho \frac{\partial}{\partial x_j}\frac{\partial}{\partial x_k} \ln{\rho},
\end{align*}

and find,
\begin{equation*}
\rho\left ( \frac{\partial}{\partial t} v_k v_j\frac{\partial v_k}{\partial x_j}\right) = -\frac{\partial p}{\partial x_k} - \frac{\partial}{\partial x_j} P_{jk} - \rho \frac{\partial}{\partial x_k}\left( \frac{V}{m} \right),
\end{equation*}
where $P_{jk} = -\frac{\hbar^2}{4m^2}\rho\frac{\partial^2\ln{\rho}}{\partial x_j \partial x_k}$. Writing this in vector notation, we obtain an equation similar to the Euler equation for an inviscid fluid,
\begin{equation}
\rho\left( \frac{\partial \mathbf{v}}{\partial t} + \left( \mathbf{v} \cdot \nabla \right)\mathbf{v} \right) = -\nabla p - \nabla \mathbf{P} - \rho \nabla \left(\frac{V}{m}\right).
\end{equation}

\end{chapter}

\begin{chapter}{Important Quantities\label{app:ImpQuantities}}
\section{\label{appsection:energy} Energy}
The energy functional of the GPE is written
\begin{equation}
\varepsilon(\psi) = \frac{\hbar^2}{2m}|\nabla\psi|^2 + \frac{g}{2}|\psi|^4 + V|\psi|^2,
\label{eq:Efn}
\end{equation}
where the first term is the kinetic energy, the second term is the energy arising from atom-atom interactions, and the final term is the energy associated with the external potential. This functional can be integrated over space to find a value for the condensate energy,
\begin{equation}
E = \int\!\varepsilon(\psi)\;\mathrm{d}\mathbf{r}
\label{eq:Efn}
\end{equation}
Equivalently, the energy of the system can be decomposed into a sum of the contributions from various types of energy in the system,
\begin{equation*}
E = E_{\rm kin} + E_{\rm int} + E_{\mathrm{pot}},
\label{eq:Esplit}
\end{equation*}
so that,
\begin{equation}
E_{\rm kin} = \int\!\frac{\hbar^2}{2m}|\nabla\psi|^2\;\mathrm{d}\mathbf{r},~E_{\rm int}=\int\!\frac{g}{2}|\psi|^4\;\mathrm{d}\mathbf{r},~E_{\mathrm{pot}}=\int\!V|\psi|^2\;\mathrm{d}\mathbf{r},
\label{eq:Esplitdef}
\end{equation}
the kinetic, interaction, and potential energies respectively.

Also of interest is the kinetic energy spectrum $\hat{E}_{\rm kin}(k)$. Using Parseval's theorem, the kinetic energy spectrum can be defined using the angle-average of $\left | \mathcal{F} \left (\sqrt{E_{\rm kin}}\ \right )\right |^2$ \cite{Nore}, where $\mathcal{F}$ denotes the Fourier transform, so that
\begin{equation}
E_{\rm kin} = \frac{1}{(2\pi)^3}\int^\infty_0\!\!\hat{E}_{\rm kin}(k)\,\mathrm{d}k.
\label{eq:Ekinspec}
\end{equation}
The kinetic energy can be further decomposed into compressible and incompressible parts,
\begin{equation*}
E_{\rm kin} = E^i_{\rm kin} + E^c_{\rm kin},
\label{eq:Esplitdef}
\end{equation*}
by using $\sqrt{\rho}v_j = (\sqrt{\rho}v_j)^c + (\sqrt{\rho}v_j)^i$, with $\nabla(\sqrt{\rho}v_j)^i=0$, where $\mathbf{v}$ is the fluid velocity. The spectrum of $E^i_{\rm kin}$ can be defined so that a similar relation to Equation \ref{eq:Ekinspec} holds.


\section{\label{appsection:force} Force}
A useful quantity to know for the study of superflow around a obstacle is the force exerted by the fluid on the obstacle, also known as the drag force. Let 
\begin{align*}
J_k &= \rho v_k,\\
p &= \frac{g}{2}\left(\frac{\rho}{m}\right)^2,\\
P_{jk} &= -\frac{\hbar^2}{4m^2} \rho \frac{\partial}{\partial x_j} \frac{\partial}{\partial x_k} \ln(\rho),\\
T_{jk} &= \rho v_j v_k + p\mathrm{\delta}_{jk} + P_{jk}.
\end{align*}
Then it can be shown that the two equations,
\begin{align}
\frac{\partial}{\partial t}\rho + \frac{\partial}{\partial x_k}J_k &= 0 \\
\frac{\partial}{\partial t}J_k + \frac{\partial}{\partial x_j}T_{jk} + \rho \frac{\partial}{\partial x_k} \left( \frac{V}{m}\right) &= 0,\label{eq:force1}
\end{align}
are equivalent to the continuity equation and modified Euler equation derived from the GPE in Section \ref{appsection:madtrans}. Now, using Equation \ref{eq:force1}, the $k$th component of the force can be written,
\begin{equation}
F_k =\frac{\partial}{\partial t} \int_V \rho v_k\,\mathrm{d}V = - \int_V \frac{\partial}{\partial x_j} T_{jk}\,\mathrm{d}V - \int_V \rho \frac{\partial}{\partial x_k} \left( \frac{V}{m} \right)\,\mathrm{d}V.
\label{eq:force}
\end{equation}

\section{\label{section:healing} Healing Length}
The characteristic length scale of a GPE based system is the healing length, $\xi$. We can directly find a expression for $\xi$ by considering the minimum length needed for a large perturbation to return to the equilibrium value. Consider only the kinetic and interaction terms in Equation \ref{eq:gpe},
\begin{equation}
  \frac{\hbar^2}{2m}\nabla^2\psi = g|\psi({\bf r},t)|^2\psi.
\end{equation}
Dimensionally we can balance these terms by replacing $\nabla^2\psi$ with $2\psi/\xi^2$, leading to
\begin{equation}
  \frac{\hbar^2}{m\xi^2} = g\rho,
\end{equation}
where $\rho = |\psi({\bf r},t)|^2$. Rearranging for $\xi$,
\begin{equation}
  \xi = \frac{\hbar}{\sqrt{mg\rho}}.
\end{equation}
\end{chapter}

\begin{chapter}{\label{app:algorithms}Algorithms}
\section{\label{appsection:vizalgos} Density/Phase Visualisation Technique}
A technique to visualise both the wavefunction phase and density is sometimes used this thesis. The advantage of the method is that it allows for an easy way to visualise the state of the phase of the system, while also retaining information about what areas of phase are unimportant due to the non-existence of fluid density in that region. Common problems with phase visualisation include the prevalence of ghost vortices\cite{tsubota_kasamatsu_02} when considering a trapped condensate; with this method the discontinuities introduced by ghost vortices are entirely unseen. Previously, this has been attained through the use of masks to hide the unimportant phase regions in trapped systems. These masks are quite arbitrary in nature and an overzealous mask may hide details. Additionally, any condensate with a breathing mode or centre of mass oscillation will periodically extend beyond a hard coded mask. The method outlined in this section instead smoothly hides the unwanted areas of phase by using the density information in the system, disregarding the need for masks completely.
\subsubsection{Plotting Algorithm}
Initially, the phase plotting is performed as normal, a process involving a conversion of a set of values in the region $[-\pi,\pi)$ to an image (defined as a 2D grid of pixels of size $n\times m$). Examples include MATLAB's image/pcolor commands or gnuplot's splot command. It is recommended, but not required, that a periodic colourmap (such as MATLAB's `hsv') of equal lightness is used. The $n \times m$ pixels obtained from this procedure will most commonly be stored in the {\tt rgb} format, a triad of values $(r,g,b)$ corresponding to the values of the red, green and blue intensities of the pixel respectively. For a maximum intensity of $255$ (a common format for {\tt rgb} pixels), a pixel with value $(0,0,0)$ is black, and a pixel of $(255,255,255)$ is white.

Each pixel must be instead represented in the {\tt hsl} format, a triad of values $(h,s,l)$ corresponding to the values of the hue, saturation and lightness of the pixel respectively. {\tt hsl} is most commonly represented such that $h \in [0,360)$ and $s,l \in [0,1]$. Any pixel of the form $(h,s,0)$ is black, and any pixel of the form $(h,s,1)$ is white.

For each pixel, the lightness is then modified so that for a pixel at location $(x,y)$, $l = |\psi(x,y)|^2/\max(|\psi|^2)$. Once complete, conversion back to {\tt rgb} format must presumably be performed, before finally re-plotting in one's software of choice. Areas of low density will appear in black, while areas of high density will show hues corresponding to the fluid phase at that location.

\subsubsection{Colour space conversion - {\tt rgb} to {\tt hsl}}
Given an {\tt rgb} format pixel $(r,g,b)$, rescale so that $r,g,b \in [0,1]$. The brightness of the pixel is described by $l$. Compute $m = \max(r,g,b)$, $n = \min(r,g,b)$ and set $l = (m+n)/2$. The hue of the pixel is described by $h$ and the strength of that hue is given by $s$. These quantities depend on the previously calculated $m$ and $n$. If $m=n$ then the pixel is achromatic and $h=s=0$, otherwise,
\begin{equation}
s =
    \begin{cases}
      \frac{m-n}{2 - m - n} &\mbox{if } l \leq 0.5 \\
      \frac{m-n}{m+n} &\mbox{if } l > 0.5,
    \end{cases}
\end{equation}
\begin{equation}
h =
    \begin{cases}
      60(\frac{g-b}{m-n}) &\mbox{if } m=r \\
      60(\frac{b-r}{m-n}+2) &\mbox{if } m=g \\
      60(\frac{r-g}{m-n}+4) &\mbox{if } m=b.
    \end{cases}
\end{equation}
The resulting triad $(h,s,l)$ then describes the required pixel in {\tt hsl} format.

\subsubsection{Colour space conversion - {\tt hsl} to {\tt rgb}}
Given a {\tt hsl} format pixel $(h,s,l)$, compute $c = (1 - | 2l - 1|) \times s$ and $h' = h/60$. Using these quantities, calculate $x = c(1-|h' \mod 2 - 1|)$. To obtain values for $r'$, $g'$ and $b'$, substitute $c$ and $x$ into
\begin{equation}
(r', g', b') =
    \begin{cases}
      (c, x, 0) &\mbox{if } 0 \leq h' < 1 \\
      (x, c, 0) &\mbox{if } 1 \leq h' < 2 \\
      (0, c, x) &\mbox{if } 2 \leq h' < 3 \\
      (0, x, c) &\mbox{if } 3 \leq h' < 4 \\
      (x, 0, c) &\mbox{if } 4 \leq h' < 5 \\
      (c, 0, x) &\mbox{if } 5 \leq h'< 6.
    \end{cases}
\end{equation}
Compute $m = l - c/2$ and substitute $m$ into $(r,g,b) = (r'+m,g'+m,b'+m)$. The resulting triad $(r,g,b)$ is then the required pixel described in {\tt rgb} format.

\section{\label{appsection:numericalalgos} Other Numerical Algorithms}
\begin{algorithm}
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \Input{Threshold value $\Delta$, step size $c$, interaction strength $g$, initial chemical potential $\mu_0$}
    \Output{Chemical potential $\mu$}
    \SetKw{KwIn}{in}
    \SetKw{KwAll}{all}
    \SetKwFunction{Abs}{abs}
    \SetKw{KwAllPoints}{all points}
    \BlankLine
    \Repeat{$\mathrm{abs}(\mu_1 -\mu_0) < \Delta$}{
    	$\mu_1 = \mu_0$\;
    	$\psi\leftarrow$ Numerically find the ground state for $g$ and $\mu_0$ using imaginary time propagation\;
    	$n_0\leftarrow \mathrm{norm}(\psi)$\;
    	$\psi\leftarrow$ Propagate in real time with dissipation $\gamma = 0.1$\;
    	$n_1\leftarrow \mathrm{norm}(\psi)$\;
    	\If{$n_1 > n_0$}{
				$\mu_0 = \mu_0 - c\times$\Abs{$n_1 - n_0$}\;
			}
			\If{$n_1 < n_0$}{
				$\mu_0 = \mu_0 + c\times$\Abs{$n_1 - n_0$}\;
			}
    }
    $\mu\leftarrow\mu_0$\;
  \caption{An optimisation algorithm to find a chemical potential, $\mu$ (to within $\pm\Delta$), so that the equilibrium state approached by the DGPE has the correct atom number. $c$ is a small constant, used to allow for a trade-off between convergence and running time (similar to gradient decent methods).}\label{algo_mu}
\end{algorithm}
\begin{algorithm}
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \Input{An initial field $\psi$, a step size $h$, optional phase profile $\Theta$}
    \SetKw{KwIn}{in}
    \SetKw{KwAll}{all}
    \SetKw{KwAllPoints}{all points}
    \BlankLine
    $t \leftarrow 0$, $dt \leftarrow -ih$\;
    \Repeat{a suitable ground state is found}{
      Perform a single step of the RK4 Scheme\;
      $t = t + dt$\;
      $n\leftarrow \mathrm{norm}(\psi)$\;
      \For{$\KwAllPoints~i~\KwIn~\psi$}{
        $\psi[i]\leftarrow \psi[i]/\sqrt{n}$\;
      }
      \If{we want a phase profile imprinted into the ground state}{
        \For{$\KwAllPoints~i~\KwIn~\psi$}{
          $\psi[i]\leftarrow \Theta[i].|\psi[i]|$\;
        }
      }
    }
    $dt = h$\;
    \Repeat{satisfied}{
      Perform a single step of the RK4 Scheme\;
      $t = t + dt$\;

      \If{real time normalisation is enabled}{
      $n\leftarrow \mathrm{norm}(\psi)$\;
      \For{$\KwAllPoints~i~\KwIn~\psi$}{
        $\psi[i]\leftarrow \psi[i]/\sqrt{n}$\;
      }
      }
    }
  \caption{RK4 algorithm for advancing a ODE/PDE in time with optional re-normalisation.}\label{algo_rk4}
\end{algorithm}

\begin{algorithm}
  \SetKwFunction{Zero}{Zero}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \Input{A $n_x \times n_y$ phase profile $\theta$. A line integral width $l$.}
  \Output{A `vortex field' $Q$.}
  \BlankLine
  \For{$i\leftarrow 1+l/2$ \KwTo $n_x-l/2$}{
    \For{$i\leftarrow 1+l/2$ \KwTo $n_y-l/2$}{
      $Q[i,j]\leftarrow \oint_{C_{[i,j]}} \nabla\theta~ds$, where $C_{[i,j]}$ is a square loop of width $l$ centred on point $[i,j]$\;
    }
  }
\caption{Vortex detection. Outputs a field with positive values near a vortex with circulation 1, negative values near a vortex with circulation -1 and zero valued otherwise. This algorithm will detect ghost vortices.}\label{algo_calcvortexfield}
\end{algorithm}

\begin{algorithm}
  \SetKwFunction{Zero}{Zero}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwData{Mtmp}{m}
  \SetKwFunction{Max}{max}
  \SetKwFunction{Min}{min}
  \SetKw{continue}{continue}
  \SetKw{KwAnd}{and}
  \SetKw{KwIn}{in}
  \SetKw{KwAll}{all}
  \SetKw{KwAllPoints}{all points}
  \Input{A $n_x \times n_y$ binary field $P$.}
  \Output{A $n_x \times n_y$ field $Q$.}
  \BlankLine
  Let $L$ be a $4 \times (n_x.n_y)$ field\;
  Let $A$ be a vector length $4$\;
  \lFor{$\KwAllPoints~i,j~\KwIn~L$}{
  $L[i,j]\leftarrow-1$
  }
  \lFor{$\KwAllPoints~i,j~\KwIn~Q$}{
  $Q[i,j]\leftarrow-1$
  }

  $l_c\leftarrow 1$, $r_c\leftarrow 0$\;

  \For{$i\leftarrow 2$ \KwTo $n_x-1$}{
    \For{$j\leftarrow 2$ \KwTo $n_y-1$}{
      \lIf {$P[i,j] = 0$}{\continue}
      $A \leftarrow (Q[i+1,j-1],Q[i,j-1],Q[i-1,j-1],Q[i-1,j])$\;
      \For{$c \leftarrow 1$ \KwTo $4$}{
        \If {$A[c]\geq 0$}{
          $Q[i,j]\leftarrow A[c]$\;
          $L[c,l_c]\leftarrow A[c]$\;
        }
      }
      \lIf{$Q[i,j] \geq 0$}{$l_c\leftarrow lc+ 1$}
      \Else{
        $Q[i,j]\leftarrow r_c $\;
        $rc \leftarrow r_c+ 1$\;
      }
    }
  }
  \For{$r\leftarrow 1$ \KwTo $(n_x.n_y)$}{
    \lIf{\Max{elements of $L$ in row $r$}$= -1$}{\continue}
    $m\leftarrow$ \Min{elements of $L$ in row $r$ with value $\geq 0$}\;

    \For{$c\leftarrow 1$ \KwTo $4$}{
      \If{$L[c,r] \neq m$ \KwAnd $L[c,r] \geq 0$ }{
        \For{$\KwAllPoints~i~\KwIn~Q$}{
          \lIf{$Q[i]=L[c,r]$}{$Q[i] \leftarrow m$}
        }
      }
    }
  }
\caption{The B/W Label algorithm. Outputs a field with the same non-zero regions of the input binary field, but with each connected region labeled with a unique value.}\label{algo_bwlabel}
\end{algorithm}

\begin{algorithm}
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \SetKw{KwIn}{in}
    \SetKw{KwAll}{all}
    \SetKw{KwAllPoints}{all points}
    \Input{A $n_x \times n_y$ field $Q$, a Gaussian filter width $g$.}
    \Output{A $n_x \times n_y$ field $G$.}
    \BlankLine
    \For{$k\leftarrow 1$ \KwTo $n_x$}{
      \For{$l\leftarrow 1$ \KwTo $n_y$}{
        \For{$i\leftarrow 1$ \KwTo $n_x$}{
          \For{$j\leftarrow 1$ \KwTo $n_y$}{
            $G[k,l] \leftarrow G[k,l] + Q[i,j]\times\exp\left (-[(k-i)^2+(l-j)^2]/g^2 \right )$\;
          }
        }
        $G[k,l] \leftarrow G[k,l]/(n_x.n_y)$\;
      }
    }

  \caption{Gaussian convolution. Filters out features with structures of size less than the input
  filter width. The output is analogous to a `blurring' of the input field. This allows high frequency noise to be removed.}\label{algo_gaussconv}
\end{algorithm}

\begin{algorithm}
  \SetKwFunction{Zero}{Zero}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwFunction{Max}{max}
  \Input{A $n_x \times n_y$ density profile $R$, A $n_x \times n_y$ phase profile $\theta$. A line integral width $l$.}
  \Output{A `vortex field' $Q$.}
  \BlankLine
  \For{$i\leftarrow 1+l/2$ \KwTo $n_x-l/2$}{
    \For{$i\leftarrow 1+l/2$ \KwTo $n_y-l/2$}{
      $S\leftarrow R(i,j)/$\Max{$R$}\;
      $Q[i,j]\leftarrow S\times\oint_{C_{[i,j]}} \nabla\theta~ds$, where $C_{[i,j]}$ is a square loop of width $l$ centred on point $[i,j]$\;
    }
  }
\caption{Improved vortex detection. Outputs a field with positive values near a vortex with circulation 1, negative values near a vortex with circulation -1 and zero valued otherwise. This method ignores ghost vortices.}\label{algo_calcvortexfielddens}
\end{algorithm}

\begin{algorithm}
  \SetKwFunction{Zero}{Zero}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwData{Linked}{linked}
  \SetKw{KwAnd}{and}
  \SetKw{KwAllPoints}{all points}
    \SetKw{KwIn}{in}
  \SetKwFunction{Max}{max}
  \SetKwFunction{Min}{min}
  \SetKwData{Call}{C}
  \Input{A $n_x \times n_y$ field $\theta$. A $n_x \times n_y$ field $P$. A threshold value $t$.}
  \Output{Number of vortices found, $n_v$. Vortex location, a $2 \times n_v $ field $V_l$. Vortex polarity, a vector $V_p$ of length $n_v$.}
  \BlankLine
  $Q\leftarrow$ Algorithm \ref{algo_gaussconv} $\leftarrow$ Algorithm \ref{algo_calcvortexfield} $\leftarrow(\theta,P)$ \;
  \lFor{$\KwAllPoints~i,j~\KwIn~R$}{
  $R[i,j]\leftarrow 0$
  }
  \lFor{$\KwAllPoints~i,j~\KwIn~S$}{
  $S[i,j]\leftarrow 0$
  }
  $n_v\leftarrow 0$\;
  \For{$i\leftarrow 1$ \KwTo $n_x$}{
    \For{$j\leftarrow 1$ \KwTo $n_y$}{
      \lIf {$Q[i,j]>t$}{$R[i,j] = 1$}
      \lIf {$Q[i,j]<t$}{$S[i,j] = 1$}
    }
  }

  \ForEach{$C\in(R,S)$}{
    $D\leftarrow$ Algorithm \ref{algo_bwlabel} $\leftarrow C$\;
    \For{$i\leftarrow 1$ \KwTo \Max($D$)}{
      $V[1,n_v]\leftarrow$ mean row of the points where $D=i$\;
      $V[2,n_v]\leftarrow$ mean column of the points where $D=i$\;
      \lIf {$C=R$}{$V[3,n_v]\leftarrow 1$}
      \lIf {$C=S$}{$V[3,n_v]\leftarrow -1$}
      $n_v \leftarrow n_v + 1$\;
    }
  }

  \caption{Calculate vortex locations and polarity.}\label{algo_calcvortexlocs}
\end{algorithm}

\begin{algorithm}
    \SetKwFunction{Zero}{Zero}
    \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
    \SetKwData{Linked}{linked}
    \SetKw{KwAnd}{and}
    \SetKwFunction{Max}{max}
    \SetKwFunction{Min}{min}
    \SetKw{continue}{continue}
    \SetKw{or}{or}
    \SetKw{In}{in}
    \SetKw{and}{and}
    \SetKwData{Call}{C}
    \Input{Vortex locations and polarity. Number of vortices, $n_v$.}
    \Output{A group number for each vortex}
    \BlankLine
    $n_{\mathrm{rca}}\leftarrow0$\;
    \While{dipoles continue to be identified}{
      \For{$i\leftarrow 1$ \KwTo $n_v$}{
        \If {vortex $i$ is mutual nearest neighbours with some other vortex $j$}{
        \If {vortex $i$ is of opposite polarity to $j$}{
            Set both vortices as group -1\;
          }
        }
      }
    }
    \While{the vortex group configuration continues to change}{
      \For{$i\leftarrow 1$ \KwTo $n_v$}{
      \For{$j\leftarrow 1$ \KwTo $n_v$}{
        \lIf {either vortex $i$ or $j$ is in group -1}{\continue}
        \If {vortex $i$ and $j$ are closer than either is to a vortex of opposite polarity}{
          \uIf {one of the two vortices $i$ and $j$ is in a group $n$}
            {Set both vortices as group $n$\;}
          \uElseIf {both vortices $i$ and $j$ are in groups $n$ and $m$}
            {Set all vortices in groups $n$ and $m$ as group \Min{$n$,$m$}\;}
          \Else{
            $n_{\mathrm{rca}} \leftarrow n_{\mathrm{rca}} + 1$\;
            Set both vortices as group $n_{\mathrm{rca}}$\;
            }
        }
      }
      }
    }

    \caption{The Recursive Cluster Algorithm. Decomposes a list of vortices into vortex dipoles or clusters. Vortices are labelled with a cluster number, with vortex dipoles labelled with $-1$.}\label{algo_rca}
\end{algorithm}

\begin{algorithm}
  \SetKwFunction{Zero}{Zero}
  \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
  \SetKwData{Linked}{linked}
  \SetKw{KwAnd}{and}
  \SetKwFunction{Max}{max}
  \SetKwFunction{Min}{min}
  \SetKwFunction{Phase}{phase}
  \SetKwData{Call}{C}
  \Input{A $n_x \times n_y$ complex field $\psi$. A `safe' distance $d$. Vortex core radius $c$. }
  \Output{A $n_x \times n_y$ complex field $\phi$.}
  \BlankLine
  $\phi \leftarrow \psi$\;
  $(n_v,V_l,V_p)\leftarrow$ Algorithm \ref{algo_calcvortexlocs}~$\leftarrow\psi$\;

  \For{$i\leftarrow 1$ \KwTo $n_v$}{
    \If{$|V_l[i]| > d$}{
      Imprint a vortex of polarity $V_p[i]$ at location $V_l[i]$ in $\phi$\;
      \For{$j\leftarrow -c$ \KwTo $c$}{
        \For{$k\leftarrow -c$ \KwTo $c$}{
            $x \leftarrow V_l[1,i]+j$\;
            $y \leftarrow V_l[2,i]+k$\;
            \mbox{$\phi(x,y) \leftarrow \psi_{\inf}~\times$~\Phase{$\psi(x,y)$}\;}
        }
      }
    }
  }

  \caption{The vortex unwinding algorithm. By accurately imprinting a vortex, this algorithm removes vortices from the input wavefunction non-destructively.}\label{algo_vortexkiller}
\end{algorithm}

\end{chapter}